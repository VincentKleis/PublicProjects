Dette er programmer som høster bilder fra internettet, de er ment for å "crawle" gjennom netsider, 
men det ble programert før jeg lærte om det på universitetet så det er en del svakheter her, 
for exemple høster disse programmen potensielt bilder det er ulåvlig å kopiere, 
og de er ikke serlig smarter, man er nødt til å programere in hvilke netsider de skal høste fra.

med hva jeg har fra universitetet kan jeg se etter /Robot.txt på alle netsider for å se om det er tillat å copiere informasjonen.
jeg kan følge linker på netsider og filtrere bilder basert på hvor på netsiden de dukker opp, 
jeg kan simulere bruker aktiviteter på netsider som knappe trykk eller venting på at netsiden laster inn
