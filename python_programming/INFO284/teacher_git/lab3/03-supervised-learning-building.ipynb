{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning \n",
    "1. Handling the data \n",
    "2. Training classifier\n",
    "3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the data\n",
    "\n",
    "Scikit learn makes it easy to load data sets into memory via simple method call.\n",
    "However in practice data sets comes in variouous formats and they might require cleaning or preprocessing. \n",
    "Data preprocessing - first it requires understandiCng of the data that you have.\n",
    "\n",
    "In this section we will learn how to load the data from both CSV files and SQL Lite files. \n",
    "\n",
    "\n",
    "CSV Loader [CSV Loader](https://docs.python.org/3/library/csv.html#reader-objects). If reading doesnt work most likely the format of the CSV needs to be reconfigured.\n",
    "\n",
    "[SQL Lite loader](https://docs.python.org/3.7/library/sqlite3.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last_name', ' \"first_name\"', ' \"SSN\"', '        \"Test1\"', ' \"Test2\"', ' \"Test3\"', ' \"Test4\"', ' \"Final\"', ' \"Grade\"']\n",
      "['Alfalfa', '   \"Aloysius\"', '   \"123-45-6789\"', ' 40.0', '    90.0', '   100.0', '    83.0', '    49.0', '   \"D-\"']\n",
      "['Alfred', '    \"University\"', ' \"123-12-1234\"', ' 41.0', '    97.0', '    96.0', '    97.0', '    48.0', '   \"D+\"']\n",
      "['Gerty', '     \"Gramma\"', '     \"567-89-0123\"', ' 41.0', '    80.0', '    60.0', '    40.0', '    44.0', '   \"C\"']\n",
      "['Android', '   \"Electric\"', '   \"087-65-4321\"', ' 42.0', '    23.0', '    36.0', '    45.0', '    47.0', '   \"B-\"']\n",
      "['Bumpkin', '   \"Fred\"', '       \"456-78-9012\"', ' 43.0', '    78.0', '    88.0', '    77.0', '    45.0', '   \"A-\"']\n",
      "['Rubble', '    \"Betty\"', '      \"234-56-7890\"', ' 44.0', '    90.0', '    80.0', '    90.0', '    46.0', '   \"C-\"']\n",
      "['Noshow', '    \"Cecil\"', '      \"345-67-8901\"', ' 45.0', '    11.0', '    -1.0', '     4.0', '    43.0', '   \"F\"']\n",
      "['Buff', '      \"Bif\"', '        \"632-79-9939\"', ' 46.0', '    20.0', '    30.0', '    40.0', '    50.0', '   \"B+\"']\n",
      "['Airpump', '   \"Andrew\"', '     \"223-45-6789\"', ' 49.0      1.0', '    90.0', '   100.0', '    83.0', '   \"A\"']\n",
      "['Backus', '    \"Jim\"', '        \"143-12-1234\"', ' 48.0', '     1.0', '    97.0', '    96.0', '    97.0', '   \"A+\"']\n",
      "['Carnivore', ' \"Art\"', '        \"565-89-0123\"', ' 44.0', '     1.0', '    80.0', '    60.0', '    40.0', '   \"D+\"']\n",
      "['Dandy', '     \"Jim\"', '        \"087-75-4321\"', ' 47.0', '     1.0', '    23.0', '    36.0', '    45.0', '   \"C+\"']\n",
      "['Elephant', '  \"Ima\"', '        \"456-71-9012\"', ' 45.0', '     1.0', '    78.0', '    88.0', '    77.0', '   \"B-\"']\n",
      "['Franklin', '  \"Benny\"', '      \"234-56-2890\"', ' 50.0', '     1.0', '    90.0', '    80.0', '    90.0', '   \"B-\"']\n",
      "['George', '    \"Boy\"', '        \"345-67-3901\"', ' 40.0', '     1.0', '    11.0', '    -1.0', '     4.0', '   \"B\"']\n",
      "['Heffalump', ' \"Harvey\"', '     \"632-79-9439\"', ' 30.0', '     1.0', '    20.0', '    30.0', '    40.0', '   \"C\"']\n",
      "Alfalfa\n",
      "Alfred\n",
      "Gerty\n",
      "Android\n",
      "Bumpkin\n",
      "Rubble\n",
      "Noshow\n",
      "Buff\n",
      "Airpump\n",
      "Backus\n",
      "Carnivore\n",
      "Dandy\n",
      "Elephant\n",
      "Franklin\n",
      "George\n",
      "Heffalump\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('grades.csv', newline='') as f:\n",
    "   reader = csv.reader(f)\n",
    "   for row in reader:\n",
    "      print(row)\n",
    "        \n",
    "with open('grades.csv', newline='') as csvfile:\n",
    "   reader = csv.DictReader(csvfile)\n",
    "   for row in reader:\n",
    "      print(row['last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Adams', 'Andrew', 'General Manager', None, '1962-02-18 00:00:00', '2002-08-14 00:00:00', '11120 Jasper Ave NW', 'Edmonton', 'AB', 'Canada', 'T5K 2N1', '+1 (780) 428-9482', '+1 (780) 428-3457', 'andrew@chinookcorp.com')\n",
      "(2, 'Edwards', 'Nancy', 'Sales Manager', 1, '1958-12-08 00:00:00', '2002-05-01 00:00:00', '825 8 Ave SW', 'Calgary', 'AB', 'Canada', 'T2P 2T3', '+1 (403) 262-3443', '+1 (403) 262-3322', 'nancy@chinookcorp.com')\n",
      "(3, 'Peacock', 'Jane', 'Sales Support Agent', 2, '1973-08-29 00:00:00', '2002-04-01 00:00:00', '1111 6 Ave SW', 'Calgary', 'AB', 'Canada', 'T2P 5M5', '+1 (403) 262-3443', '+1 (403) 262-6712', 'jane@chinookcorp.com')\n",
      "(4, 'Park', 'Margaret', 'Sales Support Agent', 2, '1947-09-19 00:00:00', '2003-05-03 00:00:00', '683 10 Street SW', 'Calgary', 'AB', 'Canada', 'T2P 5G3', '+1 (403) 263-4423', '+1 (403) 263-4289', 'margaret@chinookcorp.com')\n",
      "(5, 'Johnson', 'Steve', 'Sales Support Agent', 2, '1965-03-03 00:00:00', '2003-10-17 00:00:00', '7727B 41 Ave', 'Calgary', 'AB', 'Canada', 'T3B 1Y7', '1 (780) 836-9987', '1 (780) 836-9543', 'steve@chinookcorp.com')\n",
      "(6, 'Mitchell', 'Michael', 'IT Manager', 1, '1973-07-01 00:00:00', '2003-10-17 00:00:00', '5827 Bowness Road NW', 'Calgary', 'AB', 'Canada', 'T3B 0C5', '+1 (403) 246-9887', '+1 (403) 246-9899', 'michael@chinookcorp.com')\n",
      "(7, 'King', 'Robert', 'IT Staff', 6, '1970-05-29 00:00:00', '2004-01-02 00:00:00', '590 Columbia Boulevard West', 'Lethbridge', 'AB', 'Canada', 'T1K 5N8', '+1 (403) 456-9986', '+1 (403) 456-8485', 'robert@chinookcorp.com')\n",
      "(8, 'Callahan', 'Laura', 'IT Staff', 6, '1968-01-09 00:00:00', '2004-03-04 00:00:00', '923 7 ST NW', 'Lethbridge', 'AB', 'Canada', 'T1H 1Y8', '+1 (403) 467-3351', '+1 (403) 467-8772', 'laura@chinookcorp.com')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('chinook.db')\n",
    "for row in conn.execute('SELECT * FROM employees'):\n",
    "   print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with texual data\n",
    "Tokenizing \n",
    "Dictionary\n",
    "NLTK https://www.nltk.org/api/nltk.tokenize.html\n",
    "https://www.nltk.org/api/nltk.stem.html\n",
    "https://docs.python.org/3/tutorial/datastructures.html\n",
    "Dictionaries are sometimes found in other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified in place using index assignments, slice assignments, or methods like append() and extend().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'originated', 'from', 'the', 'idea', 'that', 'there', 'are', 'readers', 'who', 'prefer', 'learning', 'new', 'skills', 'from', 'the', 'comforts', 'of', 'their', 'drawing', 'rooms']\n",
      "program  :  program\n",
      "programs  :  program\n",
      "programer  :  program\n",
      "programing  :  program\n",
      "programers  :  program\n",
      "gallahad the pure\n",
      "robin the brave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Than Htut Soe\n",
      "[nltk_data]     UIB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tonenizing words\n",
    "import nltk\n",
    "nltk.download('punkt') #download the tokenizer data\n",
    "\n",
    "word_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\"\n",
    "nltk_tokens = nltk.word_tokenize(word_data)\n",
    "print (nltk_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "programer  :  program\n",
      "programing  :  program\n",
      "programers  :  program\n"
     ]
    }
   ],
   "source": [
    "#stemming with porter stemmer\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "  \n",
    "# choose some words to be stemmed \n",
    "words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", ps.stem(w)) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gallahad the pure\n",
      "robin the brave\n"
     ]
    }
   ],
   "source": [
    "knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n",
    "for k, v in knights.items():\n",
    "   print(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 download the mushroom dataset and use kNN from scikit learn\n",
    "[Dowload the dataset](https://www.kaggle.com/uciml/mushroom-classification)\n",
    "Read the dataset and select a few features to use with KNN to identify whether a mushrom is edible or posinous.\n",
    "Load the dataset into python code, spilt into train and test sets.\n",
    "After that train a kNN classifier from scikit using the data.\n",
    "And measure the performance of your classifier.\n",
    "Fill the answer in the book below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill your answer for exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Using the same test and training set and the same set of features, train a naive bayes classifier from it.\n",
    "Measure the performance of your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill your answer for exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting data\n",
    "Data serialization is the process of converting structured data to a format that allows sharing or storage of the data in a form that allows recovery of its original structure. In some cases, the secondary intention of data serialization is to minimize the data’s size which then reduces disk space or bandwidth requirements. When you train a model, the parameters that we have computed from training should be stored so that it will persist when you close your machine learning program.\n",
    "\n",
    "There are multple ways to serialize data. We can look at the python only way of serialization called Pickle and language dependent way called Protocol buffers.\n",
    "https://docs.python.org/2/library/pickle.html \n",
    "https://developers.google.com/protocol-buffers/docs/pythontutorial\n",
    "Protocol Buffers are an efficient (storage and processing) to store structred data.\n",
    "\n",
    "Using either pickle or protocol buffer, store the following structred data into a file and reread the file.\n",
    "{\"dictionary\" =>  { \"word1\": \"12\", \"word2\": \"33\", \"word3\" : \"31\" } ,\n",
    " \"classPrior\" => {\"positive\" : 0.5, \"negative\" : 0.5},\n",
    " \"wordLikelihood\" => {\"word\": \"word1\", \"class\":\"positive\" => \"likelihood\": 0.1 },{\"word\": \"word2\", \"class\":\"negative\" => \"likelihood\": 0.1 }\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for exiercise 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
