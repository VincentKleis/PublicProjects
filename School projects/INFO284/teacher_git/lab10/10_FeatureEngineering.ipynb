{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Feature selection\n",
    "Use the Boston housing dataset. Descriptions below taken from [here](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)\n",
    "Study the code in  [this notebook](04-representing-data-feature-engineering.ipynb) before you start. \n",
    "\n",
    "-Origin\n",
    "    The origin of the boston housing data is Natural.\n",
    "-Usage\n",
    "    This dataset may be used for Assessment.\n",
    "-Number of Cases\n",
    "    The dataset contains a total of 506 cases.\n",
    "-Order\n",
    "    The order of the cases is mysterious.\n",
    "-Variables\n",
    "    There are 14 attributes in each case of the dataset. They are:\n",
    "\n",
    "        CRIM - per capita crime rate by town\n",
    "        ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        INDUS - proportion of non-retail business acres per town.\n",
    "        CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "        NOX - nitric oxides concentration (parts per 10 million)\n",
    "        RM - average number of rooms per dwelling\n",
    "        AGE - proportion of owner-occupied units built prior to 1940\n",
    "        DIS - weighted distances to five Boston employment centres\n",
    "        RAD - index of accessibility to radial highways\n",
    "        TAX - full-value property-tax rate per $10,000\n",
    "        PTRATIO - pupil-teacher ratio by town\n",
    "        B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        LSTAT - % lower status of the population\n",
    "        MEDV - Median value of owner-occupied homes in $1000's\n",
    "        \n",
    "        \n",
    "Loading the data can be easily done with the following sklearn learn function [sklearn.datasets.load_boston](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston) \n",
    "\n",
    "Tasks\n",
    "1. List/Print all the features of the boston housing dataset. Seperate into training and test sets as usual. And perform linear regression and SVM regression using all the features. \n",
    "2. Keep the same training and test sets. First use univariate feature selection method from [this class](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html) and use half of the features. As a reference study the code in [this notebook](04-representing-data-feature-engineering.ipynb). But you dont have to add random noise to your feature as in the examples. Perform linear regression and SVM Regresion\n",
    "3. Using the same training and test sets, use recursive feature elimination with random forest classifier. The example is also in the notebook. Use it select half of the features as well and then perform the linear regression and SVM using the selected features only. \n",
    "4. Print out the features selected by both methods. Does the performance improve with feature selection? What would happen if you select more or less features in feature selection.\n",
    "\n",
    "Add your answers below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Visualization\n",
    "This time we will use the wine dataset. Load the wine dataset using this [method](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine). \n",
    "Tasks\n",
    "1. Print out all the features in the wine dataset.\n",
    "2. Use [T-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) to visualize wine dataset three classes. Use the following snippet as a reference it is from (notebook for unsupervised learning)[03-unsupervised-learning.ipynb]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: this code is not runnable\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=42)\n",
    "##### use fit_transform instead of fit, as TSNE has no transform method\n",
    "digits_tsne = tsne.fit_transform(digits.data)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.xlim(digits_tsne[:, 0].min(), digits_tsne[:, 0].max() + 1)\n",
    "plt.ylim(digits_tsne[:, 1].min(), digits_tsne[:, 1].max() + 1)\n",
    "for i in range(len(digits.data)):\n",
    "    # actually plot the digits as text instead of using scatter\n",
    "    plt.text(digits_tsne[i, 0], digits_tsne[i, 1], str(digits.target[i]),\n",
    "             color = colors[digits.target[i]],\n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "plt.xlabel(\"t-SNE feature 0\")\n",
    "plt.ylabel(\"t-SNE feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
