{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in /home/vincent/.local/lib/python3.10/site-packages (3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.83M/6.83M [00:00<00:00, 11.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep\n",
    "from networkx import Graph\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('--headless')\n",
    "s = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=s, options=op)\n",
    "G = Graph()\n",
    "\n",
    "url_oslo = 'https://twitter.com/hashtag/Oslo?src=hashtag_click'\n",
    "url_bergen = 'https://twitter.com/hashtag/Bergen?src=hashtag_click'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_hash(graph:Graph, url:str, min_len_crawl:int):\n",
    "    \"\"\"takes some url and searches for hastags to then crawl through the found hastags, \n",
    "    it visits min_len_crawl number of hashtags in addition to the original url\n",
    "\n",
    "    Args:\n",
    "        graph (Graph): networkx.Graph type object\n",
    "        url (str): start url\n",
    "        min_len_crawl (int): how many hashtags to visit.\n",
    "    \"\"\"\n",
    "\n",
    "    hashtags = []\n",
    "    visited = []\n",
    "    while len(visited) < min_len_crawl:\n",
    "        driver.get(url)\n",
    "        sleep(3)\n",
    "\n",
    "        try:\n",
    "            elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '/hashtag')]\")\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        for element in elements:\n",
    "            # extracting the hasthag link for each hashtag and removing any video or image versions of a hastag\n",
    "            hashtag = element.get_attribute('href').split('&')[0]\n",
    "            \n",
    "            if hashtag not in hashtags:\n",
    "                hashtags.append(hashtag)\n",
    "\n",
    "            if url != hashtag:\n",
    "                graph.add_edge('#'+url[28:-18], '#'+hashtag[28:-18])\n",
    "        \n",
    "        # make a list of hastags and always visit the oldest hastag\n",
    "        url = hashtags[0]\n",
    "        visited.append(hashtags.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m crawl_hash(G, url_oslo, \u001b[39m20\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m crawl_hash(G, url_bergen, \u001b[39m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m, in \u001b[0;36mcrawl_hash\u001b[0;34m(graph, url, min_len_crawl)\u001b[0m\n\u001b[1;32m     30\u001b[0m         graph\u001b[39m.\u001b[39madd_edge(\u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39murl[\u001b[39m28\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m18\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mhashtag[\u001b[39m28\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m18\u001b[39m])\n\u001b[1;32m     32\u001b[0m \u001b[39m# make a list of hastags and always visit the oldest hastag\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m url \u001b[39m=\u001b[39m hashtags[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     34\u001b[0m visited\u001b[39m.\u001b[39mappend(hashtags\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "crawl_hash(G, url_oslo, 20)\n",
    "crawl_hash(G, url_bergen, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import write_graphml\n",
    "write_graphml(G, 'OBHashtags.graphml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
